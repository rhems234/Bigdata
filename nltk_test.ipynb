{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 말뭉치 가져오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download('book',quiet=True)\n",
    "from nltk.book import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.corpus.gutenberg.fileids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emma_raw = nltk.corpus.gutenberg.raw('austen-emma.txt')\n",
    "emma_raw[:1000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 토큰 생성\n",
    "- 자연어 문서에서 분석을 위해 긴 문자열을 작은 단위로 나누는 것\n",
    "- 문장 단위, 단어 단위, 정규표현 식으로 나눌 수 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 문장단위 토큰 생성\n",
    "from nltk.tokenize import sent_tokenize\n",
    "print(sent_tokenize(emma_raw[:10000])[1]) #2번째 문장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 단어단위 토큰 생성\n",
    "from nltk.tokenize import word_tokenize\n",
    "print(word_tokenize(emma_raw[50:100]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 정규표현 생성\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "retTokenize = RegexpTokenizer(\"[\\w]+\")\n",
    "retTokenize.tokenize(emma_raw[50:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 형태소 분석\n",
    "- 형태소 : 언어학에서 일정한 의미가 있는 가장 작은 말의 단위\n",
    "- 보통 자연어 처리에서 토큰을 형태소를 이용\n",
    "- 형태소 분석 : 단어로부터 어근, 접두사 접미사, 품사 등 다양한 언어적 속성을 파악하고\n",
    "이를 이용하여 형태소를 찾아내거나 처리하는 작업\n",
    "- 형태소 분석의 예 \n",
    "    - 어간 추출 \n",
    "    - 원형 복원\n",
    "    - 품사 부착\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  어간 추출 \n",
    "- PorterStemmer, LandcasterStemmer 제공\n",
    "- 어간 추출은 단순히 어미만 제거함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer, LancasterStemmer\n",
    "\n",
    "st1 = PorterStemmer()\n",
    "st2 = LancasterStemmer()\n",
    "\n",
    "words = ['fly','files','flying','flew','flown']\n",
    "print(\"Porter stemmer:\",[st1.stem(w) for w in words])\n",
    "print(\"LancasterStemmer:\",[st2.stem(w) for w in words])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list1 = []\n",
    "for w in words:\n",
    "    list1.append(st1.stem(w))\n",
    "print(list1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list2=[st1.stem(w) for w in words]\n",
    "print(list1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 원형복원\n",
    "- 같은 의미를 가지는 여러 단어를 사전형으로 통일하는 작업"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm=WordNetLemmatizer()\n",
    "[lm.lemmatize(w,'v') for w in words]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 품사부착\n",
    "- 품사는 낱말을 문법적인 기능이나 형태, 듯에 따라 구분한 것\n",
    "- 품사의 예\n",
    "    - NNP : 단순고유명사\n",
    "    - VB : 동사\n",
    "    - VBP : 동사현재형\n",
    "    - NN : 명사\n",
    "    - DT : 관형사"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tag import pos_tag\n",
    "sentence='Emma refused to permit us to obtain the redfuse permit'\n",
    "tagged_list = pos_tag(word_tokenize(sentence))\n",
    "tagged_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noun_list = [t[0] for t in tagged_list if t[1]==\"NN\"]\n",
    "noun_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list1=[]\n",
    "for t in tagged_list :\n",
    "    if t[1]=='NN':\n",
    "        list1.append(t[0])\n",
    "    else :\n",
    "        list1.append('_')\n",
    "list1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noun_list1=[t[0] if t[1]=='NN' else '-' for t in tagged_list]\n",
    "noun_list1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tag import untag\n",
    "untag_list = untag(tagged_list)\n",
    "untag_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text 클래스\n",
    "- 문서 분석에 유용한 메소드 제공"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import Text\n",
    "text = Text(retTokenize.tokenize(emma_raw))\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "text.plot(10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text.dispersion_plot(['Emma','Knightley','Frank','Jane','Harriet','Robert'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#concordance : 단어가 사용된 위치를 직접 표시하ㅁ, 문맥의 정보를 보여줌"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text.concordance('Emma') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# similar : 같은 문맥에서 주어진 단어 대신 사용된 회수가 높은 단어를 찾아줌"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text.similar(\"Emma\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text.common_contexts('Jane','her')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FreqDist\n",
    "- 문서에 사용된 단어(토큰)의 사용빈도 정보를 담는 클래스\n",
    "- vocab() 메소드로 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fd = text.vocab()\n",
    "type(fd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import FreqDist\n",
    "stopwords= ['Mr','Mr.s','Miss','Mr','Mrs','Dear','A','No','Ah','Oh']\n",
    "emma_token = pos_tag(retTokenize.tokenize(emma_raw))\n",
    "name_list=[t[0] for t in emma_token if t[1]=='NNP' and t[0] not in stopwords] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fd_name = FreqDist(name_list)\n",
    "fd_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(fd_name.N()) # 전체 단어의 수 \n",
    "print(fd_name['Emma']) # 주어진 단어에 해당하는 빈도수\n",
    "print(fd_name.freq('Emma')) # 단어의 출현 확률"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fd_name.most_common(10) # 발생빈도 높은 10가지"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install pillow --upgrade\n",
    "\n",
    "# pip install wordcloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud\n",
    "from PIL import Image\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im = Image.open('data/img.png')\n",
    "mask_arr=np.array(im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wc=WordCloud(width=1000, height=800, background_color='white', random_state=0,mask=mask_arr)\n",
    "plt.imshow(wc.generate_from_frequencies(fd_name))\n",
    "plt.axis('off')\n",
    "plt.savefig('data/wc.png')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
