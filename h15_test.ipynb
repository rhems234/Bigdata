{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 말뭉치 가져오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download('book',quiet=True)\n",
    "from nltk.book import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method CorpusReader.fileids of <PlaintextCorpusReader in 'C:\\\\Users\\\\admin\\\\AppData\\\\Roaming\\\\nltk_data\\\\corpora\\\\gutenberg'>>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.corpus.gutenberg.fileids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[Emma by Jane Austen 1816]\\n\\nVOLUME I\\n\\nCHAPTER I\\n\\n\\n'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emma_raw=nltk.corpus.gutenberg.raw('austen-emma.txt')\n",
    "emma_raw[:50]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 토큰 생성\n",
    "- 자연어 문서에서 분석을 위해 긴 문자열을 작은 단위로 나누는 것\n",
    "- 문장 단위, 단어 단위, 정규표현식으로 나눌 수 있음."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "She was the youngest of the two daughters of a most affectionate,\n",
      "indulgent father; and had, in consequence of her sister's marriage,\n",
      "been mistress of his house from a very early period.\n"
     ]
    }
   ],
   "source": [
    "# 문장단위 토큰 생성\n",
    "from nltk.tokenize import sent_tokenize\n",
    "print(sent_tokenize(emma_raw[:10000])[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Emma', 'Woodhouse', ',', 'handsome', ',', 'clever', ',', 'and', 'rich', ',', 'with', 'a']\n"
     ]
    }
   ],
   "source": [
    "# 단어 단위 토큰생상\n",
    "from nltk.tokenize import word_tokenize\n",
    "print(word_tokenize(emma_raw[50:100]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Emma', 'Woodhouse', 'handsome', 'clever', 'and', 'rich', 'with', 'a']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#정규표현식 토큰생성\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "retTokenize =RegexpTokenizer(\"[\\w]+\")\n",
    "retTokenize.tokenize(emma_raw[50:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 형태소 분석\n",
    "- 형태소 : 언어학에서 일정한 의미가 있는 가장 작은 말의 단위\n",
    "- 보통 자연어 처리에서 토큰으로 형태소를 이용\n",
    "- 형태소 분석 : 단어로부터 어근, 접두사, 접미사, 품사 등 다양한 언어적 속성을 파악하고\n",
    "이를 이용하여 형태소를 찾아내거나 처리하는 작업\n",
    "- 형태소 분석의 예\n",
    "    - 어간 추출\n",
    "    - 원형 복원\n",
    "    - 품사 부착"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 어간 추출\n",
    "- PorterStemmer, LancasterStemmer 제공\n",
    "- 어간추출은 단순히 어미만 제거함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Porter Stemmer :  ['fli', 'file', 'fli', 'fle', 'flown']\n",
      "Lancaster Stemmer: ['fly', 'fil', 'fly', 'fle', 'flown']\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import PorterStemmer, LancasterStemmer\n",
    "\n",
    "st1=PorterStemmer()\n",
    "st2=LancasterStemmer()\n",
    "\n",
    "words=['fly','files','flying','fles', 'flown']\n",
    "print(\"Porter Stemmer : \", [st1.stem(w) for w in words])\n",
    "print(\"Lancaster Stemmer:\",[st2.stem(w) for w in words])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['fli', 'file', 'fli', 'fle', 'flown']\n"
     ]
    }
   ],
   "source": [
    "list1=[]\n",
    "for w in words:\n",
    "    list1.append(st1.stem(w))\n",
    "print(list1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['fli', 'file', 'fli', 'fle', 'flown']\n"
     ]
    }
   ],
   "source": [
    "list2=[st1.stem(w) for w in words]\n",
    "print(list2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 원형복원\n",
    "- 같은 의미를 가지는 여러 단어를 사전형으로 통일하는 작업"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['fly', 'file', 'fly', 'fles', 'fly']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm = WordNetLemmatizer()\n",
    "[lm.lemmatize(w,'v') for w in words]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 품사부착\n",
    "- 품사는 낱말을 문법적인 기능이나 형태, 뜻에 따라 구분한 것\n",
    "- 품사의 예\n",
    "    - NNP : 단순고유명사\n",
    "    - VB : 동사\n",
    "    - VBP : 동사현재형\n",
    "    - NN : 명사\n",
    "    - DT : 관형사"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Emma', 'NNP'),\n",
       " ('refused', 'VBD'),\n",
       " ('to', 'TO'),\n",
       " ('permit', 'VB'),\n",
       " ('us', 'PRP'),\n",
       " ('to', 'TO'),\n",
       " ('obtain', 'VB'),\n",
       " ('the', 'DT'),\n",
       " ('refuse', 'NN'),\n",
       " ('permit', 'NN')]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tag import pos_tag\n",
    "sentence = 'Emma refused to permit us to obtain the refuse permit'\n",
    "tagged_list = pos_tag(word_tokenize(sentence))\n",
    "tagged_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NNP: noun, proper, singular\n",
      "    Motown Venneboerger Czestochwa Ranzer Conchita Trumplane Christos\n",
      "    Oceanside Escobar Kreisler Sawyer Cougar Yvette Ervin ODI Darryl CTCA\n",
      "    Shannon A.K.C. Meltex Liverpool ...\n"
     ]
    }
   ],
   "source": [
    "nltk.help.upenn_tagset('NNP')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['refuse', 'permit']"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "noun_list=[t[0] for t in tagged_list if t[1]==\"NN\"]\n",
    "noun_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['-', '-', '-', '-', '-', '-', '-', '-', 'refuse', 'permit']"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nonu_list1=[t[0] if t[1] == 'NN' else '-' for t in tagged_list]\n",
    "nonu_list1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['_', '_', '_', '_', '_', '_', '_', '_', 'refuse', 'permit']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list1=[]\n",
    "for t in tagged_list:\n",
    "    if t[1] == 'NN':\n",
    "        list1.append(t[0])\n",
    "    else:\n",
    "        list1.append('_')\n",
    "\n",
    "list1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Emma',\n",
       " 'refused',\n",
       " 'to',\n",
       " 'permit',\n",
       " 'us',\n",
       " 'to',\n",
       " 'obtain',\n",
       " 'the',\n",
       " 'refuse',\n",
       " 'permit']"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tag import untag\n",
    "untag_list=untag(tagged_list)\n",
    "untag_list"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
